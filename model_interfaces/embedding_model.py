from sentence_transformers import SentenceTransformer
from typing import List
import logging

import torch

# Configure a logger for this module
logger = logging.getLogger(__name__)
logging.basicConfig(level=logging.INFO) # Basic config, can be customized

class EmbeddingModel:
    """
    A wrapper class for handling sentence embedding models.
    This class initializes a pre-trained model and provides
    methods to generate embeddings for text.
    """
    def __init__(self):
        """
        Initializes the EmbeddingModel.

        Args:
            model_name (str): The name of the pre-trained sentence transformer model to use.
        """
        self.model_name = "BAAI/bge-code-v1"
        self.model = None
        self._load_model()
 
    def _load_model(self):
        """
        Loads the pre-trained sentence transformer model.
        Handles potential errors during model loading.
        """
        try:
            logger.info(f"Loading embedding model: {self.model_name}...")
            self.model = SentenceTransformer(
                        self.model_name,
                        trust_remote_code=True,
                        model_kwargs={"torch_dtype": torch.float16},
                    ) 
            logger.info(f"Embedding model '{self.model_name}' loaded successfully.")
        except Exception as e:
            logger.error(f"Failed to load embedding model '{self.model_name}': {e}")
            # Depending on the application's needs, you might want to re-raise the exception
            # or handle it in a way that allows the application to continue with limited functionality.
            raise RuntimeError(f"Could not initialize embedding model: {e}")

    def embed_chunks(self, text_chunks: List[str]) -> List[List[float]]:
        """
        Generates embeddings for a list of text chunks.

        Args:
            text_chunks (List[str]): A list of text strings to embed.

        Returns:
            List[List[float]]: A list of embeddings, where each embedding is a list of floats.
                               Returns an empty list if the input is empty or the model is not loaded.
        """
        if not self.model:
            logger.error("Embedding model is not loaded. Cannot generate embeddings.")
            return []
        
        if not text_chunks:
            logger.info("No text chunks provided for embedding.")
            return []

        try:
            logger.info(f"Generating embeddings for {len(text_chunks)} chunks...")
            embeddings = self.model.encode(text_chunks, show_progress_bar=True)
            logger.info("Embeddings generated successfully.")
            # Convert numpy arrays to lists of floats if necessary for storage/serialization
            return [embedding.tolist() for embedding in embeddings]
        except Exception as e:
            logger.error(f"Error during embedding generation: {e}")
            return [] # Or re-raise, depending on desired error handling

    def get_embedding_dimension(self) -> int:
        """
        Returns the dimension of the embeddings generated by the model.

        Returns:
            int: The embedding dimension, or -1 if the model is not loaded.
        """
        if not self.model:
            logger.warning("Embedding model is not loaded. Cannot determine embedding dimension.")
            return -1
        return self.model.get_sentence_embedding_dimension()

# Example usage (optional, for testing the class directly)
if __name__ == '__main__':
    try:
        print("Initializing EmbeddingModel...")
        # You might need to download the model the first time you run this.
        # Ensure you have an internet connection.
        embedder = EmbeddingModel(model_name='all-MiniLM-L6-v2') 
        
        print(f"Model: {embedder.model_name}")
        print(f"Embedding dimension: {embedder.get_embedding_dimension()}")

        sample_texts = [
            "This is the first document.",
            "This document is the second document.",
            "And this is the third one.",
            "Is this the first document?"
        ]
        
        print(f"\nEmbedding {len(sample_texts)} sample texts...")
        embeddings = embedder.embed_chunks(sample_texts)
        
        if embeddings:
            for i, (text, emb) in enumerate(zip(sample_texts, embeddings)):
                print(f"\nText: {text}")
                print(f"Embedding (first 5 dims): {emb[:5]}")
                print(f"Embedding length: {len(emb)}")
        else:
            print("No embeddings were generated.")

    except RuntimeError as e:
        print(f"Runtime Error: {e}")
    except Exception as e:
        print(f"An unexpected error occurred: {e}")

