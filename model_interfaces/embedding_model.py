from sentence_transformers import SentenceTransformer
from typing import List
import logging
from utils.logger import LOGGER

import torch


class EmbeddingModel:
    """
    A wrapper class for handling sentence embedding models.
    This class initializes a pre-trained model and provides
    methods to generate embeddings for text.
    """
    def __init__(self):
        """
        Initializes the EmbeddingModel.

        Args:
            model_name (str): The name of the pre-trained sentence transformer model to use.
        """
        self.model_name = "BAAI/bge-code-v1"
        self.model = None
        self._load_model()
 
    def _load_model(self):
        """
        Loads the pre-trained sentence transformer model.
        Handles potential errors during model loading.
        """
        try:
            LOGGER.info(f"Loading embedding model: {self.model_name}...")
            self.model = SentenceTransformer(
                        self.model_name,
                        trust_remote_code=True,
                        model_kwargs={"torch_dtype": torch.float16},
                    ) 
            LOGGER.info(f"Embedding model '{self.model_name}' loaded successfully.")
        except Exception as e:
            LOGGER.error(f"Failed to load embedding model '{self.model_name}': {e}")
            # Depending on the application's needs, you might want to re-raise the exception
            # or handle it in a way that allows the application to continue with limited functionality.
            raise RuntimeError(f"Could not initialize embedding model: {e}")

    def embed_chunks(self, text_chunks: List[str]) -> List[List[float]]:
        """
        Generates embeddings for a list of text chunks.

        Args:
            text_chunks (List[str]): A list of text strings to embed.

        Returns:
            List[List[float]]: A list of embeddings, where each embedding is a list of floats.
                               Returns an empty list if the input is empty or the model is not loaded.
        """
        if not self.model:
            LOGGER.error("Embedding model is not loaded. Cannot generate embeddings.")
            return []
        
        if not text_chunks:
            LOGGER.info("No text chunks provided for embedding.")
            return []

        try:
            LOGGER.info(f"Generating embeddings for {len(text_chunks)} chunks...")
            embeddings = self.model.encode(text_chunks, show_progress_bar=True)
            LOGGER.info("Embeddings generated successfully.")
            # Convert numpy arrays to lists of floats if necessary for storage/serialization
            return [embedding.tolist() for embedding in embeddings]
        except Exception as e:
            LOGGER.error(f"Error during embedding generation: {e}")
            return [] # Or re-raise, depending on desired error handling

    def get_embedding_dimension(self) -> int:
        """
        Returns the dimension of the embeddings generated by the model.

        Returns:
            int: The embedding dimension, or -1 if the model is not loaded.
        """
        if not self.model:
            LOGGER.warning("Embedding model is not loaded. Cannot determine embedding dimension.")
            return -1
        return self.model.get_sentence_embedding_dimension()
